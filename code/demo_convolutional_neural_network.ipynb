{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:[1.15.0].\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from util import placeholders,get_mnist,suppress_tf_warning,mlp,gpu_sess,get_vars\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format='retina'\n",
    "suppress_tf_warning()\n",
    "print (\"TF version:[%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train:[60000], n_test:[10000], x_dim:[784], y_dim:[10]\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = get_mnist()\n",
    "n_train,n_test,x_dim,y_dim = x_train.shape[0],x_test.shape[0],\\\n",
    "    x_train.shape[1],y_train.shape[1]\n",
    "print (\"n_train:[%d], n_test:[%d], x_dim:[%d], y_dim:[%d]\"%\n",
    "       (n_train,n_test,x_dim,y_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_x = tf.placeholder(dtype=tf.float32,shape=[None,784],name='x')\n",
    "ph_y = tf.placeholder(dtype=tf.float32,shape=[None,10],name='y')\n",
    "ph_is_train = tf.placeholder(tf.bool,name='is_train') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.reshape(ph_x,shape=[-1,28,28,1])\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv -> BN -> actv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.layers.conv2d(inputs=net,filters=32,kernel_size=3,padding='same',\n",
    "                       activation=None)\n",
    "net = tf.layers.max_pooling2d(inputs=net,pool_size=2,strides=2)\n",
    "net = tf.layers.batch_normalization(net,training=ph_is_train)\n",
    "net = tf.nn.relu(net)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 32) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.layers.conv2d(inputs=net,filters=32,kernel_size=3,padding='same',\n",
    "                       activation=None)\n",
    "net = tf.layers.max_pooling2d(inputs=net,pool_size=2,strides=2)\n",
    "net = tf.layers.batch_normalization(net,training=ph_is_train)\n",
    "net = tf.nn.relu(net)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten/Reshape:0' shape=(?, 1568) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.layers.flatten(net)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = mlp(net,h_dims=[128,10],actv=tf.nn.relu,out_actv=None,\n",
    "          USE_DROPOUT=True,ph_is_training=ph_is_train)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ph_y,logits=y_hat)\n",
    "cost = tf.reduce_mean(costs) \n",
    "update_ops = tf.compat.v1.get_collection(tf.GraphKeys.UPDATE_OPS) # BN\n",
    "optm = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "optm = tf.group([optm, update_ops])\n",
    "corr = tf.equal(tf.argmax(y_hat,1),tf.argmax(ph_y,1)) # [N]\n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\")) # [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpu_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accr(sess,x,y,batch_size=256):\n",
    "    n = x.shape[0] # number of data\n",
    "    accr_val_sum = 0.0\n",
    "    for it in range(np.ceil(n/batch_size).astype(np.int)):\n",
    "        x_batch = x[it*batch_size:(it+1)*batch_size,:]\n",
    "        y_batch = y[it*batch_size:(it+1)*batch_size,:]\n",
    "        feeds = {ph_x:x_batch,ph_y:y_batch,ph_is_train:False}\n",
    "        accr_val = sess.run(accr,feed_dict=feeds)\n",
    "        accr_val_sum += accr_val*x_batch.shape[0]\n",
    "    accr_val_avg = accr_val_sum/n # average out accuracy \n",
    "    return accr_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[0/20] train_accuracy:[0.961] test_accuracy:[0.964]\n",
      "epoch:[1/20] train_accuracy:[0.988] test_accuracy:[0.986]\n",
      "epoch:[2/20] train_accuracy:[0.990] test_accuracy:[0.988]\n",
      "epoch:[3/20] train_accuracy:[0.993] test_accuracy:[0.989]\n",
      "epoch:[4/20] train_accuracy:[0.995] test_accuracy:[0.990]\n",
      "epoch:[5/20] train_accuracy:[0.995] test_accuracy:[0.991]\n",
      "epoch:[6/20] train_accuracy:[0.996] test_accuracy:[0.991]\n",
      "epoch:[7/20] train_accuracy:[0.997] test_accuracy:[0.992]\n",
      "epoch:[8/20] train_accuracy:[0.996] test_accuracy:[0.992]\n",
      "epoch:[9/20] train_accuracy:[0.997] test_accuracy:[0.992]\n",
      "epoch:[10/20] train_accuracy:[0.996] test_accuracy:[0.990]\n",
      "epoch:[11/20] train_accuracy:[0.998] test_accuracy:[0.992]\n",
      "epoch:[12/20] train_accuracy:[0.998] test_accuracy:[0.993]\n",
      "epoch:[13/20] train_accuracy:[0.998] test_accuracy:[0.993]\n",
      "epoch:[14/20] train_accuracy:[0.997] test_accuracy:[0.991]\n",
      "epoch:[15/20] train_accuracy:[0.999] test_accuracy:[0.993]\n",
      "epoch:[16/20] train_accuracy:[0.999] test_accuracy:[0.992]\n",
      "epoch:[17/20] train_accuracy:[0.999] test_accuracy:[0.994]\n",
      "epoch:[18/20] train_accuracy:[0.998] test_accuracy:[0.990]\n",
      "epoch:[19/20] train_accuracy:[0.998] test_accuracy:[0.992]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # Initialize variables\n",
    "max_epoch,batch_size,print_every = 20,128,1\n",
    "max_iter = np.ceil(n_train/batch_size).astype(np.int) # number of iterations\n",
    "for epoch in range(max_epoch):\n",
    "    p_idx = np.random.permutation(n_train)\n",
    "    for it in range(max_iter):\n",
    "        b_idx = p_idx[batch_size*(it):batch_size*(it+1)]\n",
    "        x_batch,y_batch = x_train[b_idx,:],y_train[b_idx,:]\n",
    "        feeds = {ph_x:x_batch,ph_y:y_batch,ph_is_train:True}\n",
    "        sess.run(optm,feed_dict=feeds)\n",
    "    \n",
    "    if ((epoch%print_every)==0) or (epoch==(max_epoch-1)):\n",
    "        train_accr_val = get_accr(sess,x_train,y_train)\n",
    "        test_accr_val = get_accr(sess,x_test,y_test)\n",
    "        print (\"epoch:[%d/%d] train_accuracy:[%.3f] test_accuracy:[%.3f]\"%\n",
    "               (epoch,max_epoch,train_accr_val,test_accr_val))\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "class ConvNetClsClass(object):\n",
    "    \"\"\"\n",
    "    CNN for classification\n",
    "    \"\"\"\n",
    "    def __init__(self,name='CNN',x_dim=784,y_dim=10,img_dim=[28,28,1],\n",
    "                 filter_sizes=[32,32],kernel_sizes=[3,3],h_dims=[128],\n",
    "                 USE_BN=True,USE_DROPOUT=True):\n",
    "        self.name = name\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.img_dim = img_dim\n",
    "        \n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.h_dims = h_dims\n",
    "        \n",
    "        self.USE_BN = USE_BN\n",
    "        self.USE_DROPOUT = USE_DROPOUT\n",
    "        \n",
    "        self.build_model()\n",
    "        self.build_graph()\n",
    "        print(\"[%s] instantiated.\"%(self.name))\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build model\n",
    "        \"\"\"\n",
    "        self.ph_x = tf.placeholder(dtype=tf.float32,shape=[None,self.x_dim],name='x')\n",
    "        self.ph_y = tf.placeholder(dtype=tf.float32,shape=[None,self.y_dim],name='y')\n",
    "        self.ph_is_train = tf.placeholder(tf.bool,name='is_train') \n",
    "        \n",
    "        net = tf.reshape(self.ph_x,shape=[-1]+self.img_dim) # reshape\n",
    "        \n",
    "        with tf.variable_scope('main'):\n",
    "            # Conv layers\n",
    "            for (filter_size,kernel_size) in zip(self.filter_sizes,self.kernel_sizes):\n",
    "                net = tf.layers.conv2d(inputs=net,\n",
    "                                       filters=filter_size,kernel_size=kernel_size,\n",
    "                                       padding='same',activation=None)\n",
    "                net = tf.layers.max_pooling2d(inputs=net,pool_size=2,strides=2)\n",
    "                if self.USE_BN:\n",
    "                    net = tf.layers.batch_normalization(net,training=self.ph_is_train)\n",
    "                net = tf.nn.relu(net)\n",
    "\n",
    "            # Dense layers\n",
    "            net = tf.layers.flatten(net)\n",
    "            net = mlp(net,h_dims=self.h_dims+[self.y_dim],actv=tf.nn.relu,out_actv=None,\n",
    "                      USE_DROPOUT=self.USE_DROPOUT,ph_is_training=self.ph_is_train)\n",
    "        self.y_hat = net\n",
    "        self.main_vars = get_vars('main')\n",
    "        \n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        Build graph\n",
    "        \"\"\"\n",
    "        self.costs = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=self.ph_y,logits=self.y_hat)\n",
    "        self.cost = tf.reduce_mean(self.costs) \n",
    "        self.update_ops = tf.compat.v1.get_collection(tf.GraphKeys.UPDATE_OPS) # BN\n",
    "        self.optm = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(self.cost)\n",
    "        self.optm = tf.group([self.optm,self.update_ops])\n",
    "        self.corr = tf.equal(tf.argmax(self.y_hat,1),tf.argmax(self.ph_y,1)) # [N]\n",
    "        self.accr = tf.reduce_mean(tf.cast(self.corr, \"float\")) # [1]\n",
    "        \n",
    "    def update(self,sess,x_batch,y_batch):\n",
    "        \"\"\"\n",
    "        Update model \n",
    "        \"\"\"\n",
    "        feeds = {self.ph_x:x_batch,self.ph_y:y_batch,self.ph_is_train:True}\n",
    "        cost_val,_ = sess.run([self.cost,self.optm],feed_dict=feeds)\n",
    "        return cost_val\n",
    "    \n",
    "    def get_accr(self,sess,x,y,batch_size=256):\n",
    "        n = x.shape[0] # number of data\n",
    "        accr_val_sum = 0.0\n",
    "        for it in range(np.ceil(n/batch_size).astype(np.int)):\n",
    "            x_batch = x[it*batch_size:(it+1)*batch_size,:]\n",
    "            y_batch = y[it*batch_size:(it+1)*batch_size,:]\n",
    "            feeds = {self.ph_x:x_batch,self.ph_y:y_batch,self.ph_is_train:False}\n",
    "            accr_val = sess.run(self.accr,feed_dict=feeds)\n",
    "            accr_val_sum += accr_val*x_batch.shape[0]\n",
    "        accr_val_avg = accr_val_sum/n # average out accuracy \n",
    "        return accr_val_avg\n",
    "        \n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN] instantiated.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = gpu_sess() # open session\n",
    "C = ConvNetClsClass(name='CNN',x_dim=784,y_dim=10,img_dim=[28,28,1],\n",
    "                    filter_sizes=[32,32],kernel_sizes=[3,3],h_dims=[128],\n",
    "                    USE_BN=True,USE_DROPOUT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <tf.Variable 'main/conv2d/kernel:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n",
      "1 <tf.Variable 'main/conv2d/bias:0' shape=(32,) dtype=float32_ref>\n",
      "2 <tf.Variable 'main/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "3 <tf.Variable 'main/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>\n",
      "4 <tf.Variable 'main/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>\n",
      "5 <tf.Variable 'main/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>\n",
      "6 <tf.Variable 'main/conv2d_1/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>\n",
      "7 <tf.Variable 'main/conv2d_1/bias:0' shape=(32,) dtype=float32_ref>\n",
      "8 <tf.Variable 'main/batch_normalization_1/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "9 <tf.Variable 'main/batch_normalization_1/beta:0' shape=(32,) dtype=float32_ref>\n",
      "10 <tf.Variable 'main/batch_normalization_1/moving_mean:0' shape=(32,) dtype=float32_ref>\n",
      "11 <tf.Variable 'main/batch_normalization_1/moving_variance:0' shape=(32,) dtype=float32_ref>\n",
      "12 <tf.Variable 'main/dense/kernel:0' shape=(1568, 128) dtype=float32_ref>\n",
      "13 <tf.Variable 'main/dense/bias:0' shape=(128,) dtype=float32_ref>\n",
      "14 <tf.Variable 'main/dense_1/kernel:0' shape=(128, 10) dtype=float32_ref>\n",
      "15 <tf.Variable 'main/dense_1/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for v_idx,var in enumerate(C.main_vars):\n",
    "    print (v_idx,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[0/20] train_accuracy:[0.964] test_accuracy:[0.968]\n",
      "epoch:[1/20] train_accuracy:[0.988] test_accuracy:[0.985]\n",
      "epoch:[2/20] train_accuracy:[0.989] test_accuracy:[0.987]\n",
      "epoch:[3/20] train_accuracy:[0.991] test_accuracy:[0.988]\n",
      "epoch:[4/20] train_accuracy:[0.994] test_accuracy:[0.990]\n",
      "epoch:[5/20] train_accuracy:[0.995] test_accuracy:[0.992]\n",
      "epoch:[6/20] train_accuracy:[0.996] test_accuracy:[0.990]\n",
      "epoch:[7/20] train_accuracy:[0.996] test_accuracy:[0.991]\n",
      "epoch:[8/20] train_accuracy:[0.997] test_accuracy:[0.992]\n",
      "epoch:[9/20] train_accuracy:[0.995] test_accuracy:[0.990]\n",
      "epoch:[10/20] train_accuracy:[0.997] test_accuracy:[0.992]\n",
      "epoch:[11/20] train_accuracy:[0.996] test_accuracy:[0.989]\n",
      "epoch:[12/20] train_accuracy:[0.996] test_accuracy:[0.990]\n",
      "epoch:[13/20] train_accuracy:[0.998] test_accuracy:[0.992]\n",
      "epoch:[14/20] train_accuracy:[0.999] test_accuracy:[0.992]\n",
      "epoch:[15/20] train_accuracy:[0.999] test_accuracy:[0.993]\n",
      "epoch:[16/20] train_accuracy:[0.998] test_accuracy:[0.993]\n",
      "epoch:[17/20] train_accuracy:[0.999] test_accuracy:[0.992]\n",
      "epoch:[18/20] train_accuracy:[0.999] test_accuracy:[0.992]\n",
      "epoch:[19/20] train_accuracy:[0.999] test_accuracy:[0.991]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # Initialize variables\n",
    "max_epoch,batch_size,print_every = 20,128,1\n",
    "max_iter = np.ceil(n_train/batch_size).astype(np.int) # number of iterations\n",
    "for epoch in range(max_epoch):\n",
    "    p_idx = np.random.permutation(n_train)\n",
    "    for it in range(max_iter):\n",
    "        b_idx = p_idx[batch_size*(it):batch_size*(it+1)]\n",
    "        x_batch,y_batch = x_train[b_idx,:],y_train[b_idx,:]\n",
    "        C.update(sess,x_batch,y_batch)\n",
    "    \n",
    "    if ((epoch%print_every)==0) or (epoch==(max_epoch-1)):\n",
    "        train_accr_val = C.get_accr(sess,x_train,y_train)\n",
    "        test_accr_val = C.get_accr(sess,x_test,y_test)\n",
    "        print (\"epoch:[%d/%d] train_accuracy:[%.3f] test_accuracy:[%.3f]\"%\n",
    "               (epoch,max_epoch,train_accr_val,test_accr_val))\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
